{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 736 samples, validate on 184 samples\n",
      "Epoch 1/20\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.2211 - acc: 0.9239WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\testAI\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "736/736 [==============================] - 12s 16ms/sample - loss: 0.2211 - acc: 0.9239 - val_loss: 5.8549 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "736/736 [==============================] - 12s 16ms/sample - loss: 0.0616 - acc: 0.9810 - val_loss: 4.7120 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "736/736 [==============================] - 13s 17ms/sample - loss: 0.0534 - acc: 0.9878 - val_loss: 4.6924 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "736/736 [==============================] - 12s 16ms/sample - loss: 0.0084 - acc: 0.9986 - val_loss: 6.4747 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "736/736 [==============================] - 12s 16ms/sample - loss: 3.2355e-04 - acc: 1.0000 - val_loss: 7.2251 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "736/736 [==============================] - 12s 16ms/sample - loss: 4.3112e-04 - acc: 1.0000 - val_loss: 7.1698 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "736/736 [==============================] - 13s 18ms/sample - loss: 2.3464e-04 - acc: 1.0000 - val_loss: 7.3562 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "736/736 [==============================] - 16s 21ms/sample - loss: 2.9266e-05 - acc: 1.0000 - val_loss: 7.5269 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "736/736 [==============================] - 15s 21ms/sample - loss: 1.4191e-05 - acc: 1.0000 - val_loss: 7.6318 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "736/736 [==============================] - 14s 19ms/sample - loss: 7.5059e-05 - acc: 1.0000 - val_loss: 7.5328 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "736/736 [==============================] - 14s 19ms/sample - loss: 2.2469e-05 - acc: 1.0000 - val_loss: 7.5026 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "736/736 [==============================] - 13s 18ms/sample - loss: 1.8887e-05 - acc: 1.0000 - val_loss: 7.2850 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "736/736 [==============================] - 13s 18ms/sample - loss: 1.2931e-05 - acc: 1.0000 - val_loss: 6.6824 - val_acc: 0.0054\n",
      "Epoch 14/20\n",
      "736/736 [==============================] - 13s 17ms/sample - loss: 6.5748e-06 - acc: 1.0000 - val_loss: 5.3725 - val_acc: 0.0435\n",
      "Epoch 15/20\n",
      "736/736 [==============================] - 13s 17ms/sample - loss: 6.4435e-06 - acc: 1.0000 - val_loss: 3.5999 - val_acc: 0.1848\n",
      "Epoch 16/20\n",
      "736/736 [==============================] - 13s 18ms/sample - loss: 7.8313e-06 - acc: 1.0000 - val_loss: 1.7799 - val_acc: 0.4783\n",
      "Epoch 17/20\n",
      "736/736 [==============================] - 13s 17ms/sample - loss: 6.7521e-06 - acc: 1.0000 - val_loss: 0.4623 - val_acc: 0.7935\n",
      "Epoch 18/20\n",
      "736/736 [==============================] - 13s 18ms/sample - loss: 4.7485e-06 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9728\n",
      "Epoch 19/20\n",
      "736/736 [==============================] - 12s 17ms/sample - loss: 5.3755e-06 - acc: 1.0000 - val_loss: 0.0608 - val_acc: 0.9837\n",
      "Epoch 20/20\n",
      "736/736 [==============================] - 12s 17ms/sample - loss: 4.5071e-06 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9837\n",
      "[[9.99999642e-01 1.84561031e-07 1.22494614e-09 8.42889420e-08]\n",
      " [9.99999523e-01 2.96749107e-07 1.98868966e-09 2.04967776e-07]\n",
      " [9.99998212e-01 2.58583583e-07 4.06987404e-08 1.52959933e-06]\n",
      " [9.99993205e-01 1.64866890e-06 4.28075481e-07 4.59779221e-06]\n",
      " [9.99793708e-01 4.26150000e-05 1.32582306e-06 1.62350931e-04]\n",
      " [9.18876767e-01 7.85673782e-02 6.95131894e-04 1.86077517e-03]\n",
      " [9.03908789e-01 9.32598785e-02 5.58759086e-04 2.27269181e-03]\n",
      " [9.99971986e-01 2.41302751e-05 1.50975893e-07 3.86821876e-06]\n",
      " [1.00000000e+00 1.28230209e-08 5.65406263e-11 2.43985898e-09]\n",
      " [1.00000000e+00 7.52791962e-09 3.56264809e-11 1.73438131e-09]\n",
      " [1.00000000e+00 8.98376040e-09 9.48348552e-11 3.88970323e-09]\n",
      " [9.99999881e-01 1.13888625e-07 2.02247863e-09 3.27747820e-08]\n",
      " [1.00000000e+00 3.46089521e-08 3.17872284e-10 4.65589789e-09]\n",
      " [1.00000000e+00 4.54573055e-08 4.17487905e-10 5.40301714e-09]\n",
      " [1.00000000e+00 2.09415223e-08 2.39546133e-10 4.57939775e-09]\n",
      " [1.00000000e+00 4.05600176e-08 4.19765944e-10 7.42463735e-09]\n",
      " [1.00000000e+00 5.32895186e-08 6.44203912e-10 1.11438725e-08]\n",
      " [1.00000000e+00 4.10051086e-08 5.39029210e-10 9.10235798e-09]\n",
      " [1.00000000e+00 2.18410428e-08 2.33594838e-10 2.77203571e-09]\n",
      " [1.00000000e+00 2.38790498e-08 2.60573979e-10 2.83774026e-09]\n",
      " [1.24645958e-04 9.99842644e-01 6.28066630e-07 3.20506770e-05]\n",
      " [8.74289071e-06 9.99989033e-01 1.68036447e-08 2.26149700e-06]\n",
      " [6.73044415e-05 9.99917865e-01 2.11912933e-07 1.44834103e-05]\n",
      " [5.84930422e-05 9.99929667e-01 1.66604522e-07 1.17327299e-05]\n",
      " [3.52653093e-04 9.99598920e-01 1.10226222e-06 4.74146254e-05]\n",
      " [2.99447856e-05 9.99960423e-01 6.66983198e-08 9.49568675e-06]\n",
      " [2.67499738e-04 9.99713719e-01 4.57532423e-07 1.82678796e-05]\n",
      " [2.39610759e-04 9.99743164e-01 4.04746316e-07 1.68494389e-05]\n",
      " [3.98769218e-04 9.99586403e-01 4.70882753e-07 1.43524321e-05]\n",
      " [9.45526990e-05 9.99901175e-01 9.49901775e-08 4.11474048e-06]\n",
      " [3.99809767e-04 9.99552667e-01 1.86438308e-06 4.55952650e-05]\n",
      " [4.63711534e-04 9.99524832e-01 4.04804581e-07 1.10621204e-05]\n",
      " [2.36864464e-04 9.99753058e-01 2.45291034e-07 9.91559955e-06]\n",
      " [3.98520438e-04 9.99582231e-01 5.75248521e-07 1.86591551e-05]\n",
      " [2.42058115e-04 9.99744833e-01 3.33782424e-07 1.27383100e-05]\n",
      " [2.14736373e-03 9.97758746e-01 5.11567305e-06 8.87577189e-05]\n",
      " [1.26048061e-03 9.98629689e-01 2.49851632e-06 1.07377586e-04]\n",
      " [1.00867089e-03 9.98913884e-01 1.95908046e-06 7.55524088e-05]\n",
      " [1.40140660e-03 9.98512685e-01 6.91025343e-06 7.90143822e-05]\n",
      " [3.01683904e-03 9.96814787e-01 1.60537329e-05 1.52335939e-04]\n",
      " [4.24379152e-12 2.09160421e-13 1.00000000e+00 3.20541098e-12]\n",
      " [2.31584545e-06 4.79874416e-08 9.99997020e-01 5.69411100e-07]\n",
      " [3.52334268e-06 9.54568691e-08 9.99995708e-01 6.79579102e-07]\n",
      " [2.86255492e-10 1.99858637e-11 1.00000000e+00 6.93686358e-11]\n",
      " [2.74339618e-06 6.00918710e-08 9.99996662e-01 4.99382338e-07]\n",
      " [6.17549040e-06 1.20793928e-07 9.99992728e-01 9.50408776e-07]\n",
      " [2.78988637e-07 6.19089047e-09 9.99999642e-01 1.24680085e-07]\n",
      " [3.18163771e-08 7.84626975e-10 1.00000000e+00 2.11017834e-08]\n",
      " [1.37361482e-07 3.00765568e-09 9.99999762e-01 6.36776960e-08]\n",
      " [5.17689250e-06 1.16332416e-07 9.99994278e-01 4.88120577e-07]\n",
      " [1.38841438e-06 2.89930320e-08 9.99998450e-01 1.58873931e-07]\n",
      " [5.93172480e-08 1.36600276e-09 9.99999881e-01 3.80449485e-08]\n",
      " [1.19568767e-07 2.63431477e-09 9.99999762e-01 6.96075588e-08]\n",
      " [1.18914777e-07 2.74613821e-09 9.99999762e-01 8.84907223e-08]\n",
      " [7.50847448e-07 1.46679833e-08 9.99998927e-01 3.03155502e-07]\n",
      " [2.98162952e-08 7.32173433e-10 1.00000000e+00 1.81179853e-08]\n",
      " [3.73409890e-08 8.54034010e-10 1.00000000e+00 2.30506192e-08]\n",
      " [1.74943386e-06 3.12844080e-08 9.99997735e-01 5.06603499e-07]\n",
      " [1.64312332e-05 3.10145055e-07 9.99979377e-01 3.90757941e-06]\n",
      " [8.04542495e-08 2.42558618e-09 9.99999881e-01 5.13805460e-08]\n",
      " [1.07289992e-01 9.63913836e-03 2.09583246e-04 8.82861257e-01]\n",
      " [6.60640410e-07 6.17515866e-07 7.50694795e-09 9.99998689e-01]\n",
      " [5.89462843e-06 3.06384072e-06 4.30552092e-08 9.99990940e-01]\n",
      " [1.14635382e-04 9.40787577e-05 8.70298720e-07 9.99790490e-01]\n",
      " [3.71201604e-05 9.54685675e-06 2.17398082e-07 9.99953151e-01]\n",
      " [2.17848501e-04 9.36950310e-05 1.60351317e-06 9.99686837e-01]\n",
      " [2.84043836e-05 1.18876642e-05 3.13105033e-07 9.99959350e-01]\n",
      " [1.79249741e-06 6.18739591e-07 9.34079125e-09 9.99997616e-01]\n",
      " [1.18573723e-06 1.08238999e-06 1.30818405e-08 9.99997735e-01]\n",
      " [9.47830983e-07 5.28320243e-07 1.38019907e-08 9.99998569e-01]\n",
      " [9.51668153e-06 2.49892446e-06 4.24949960e-08 9.99987960e-01]\n",
      " [3.07052642e-01 2.04645880e-02 4.78859380e-04 6.72003984e-01]\n",
      " [3.47202513e-05 5.11273174e-06 1.30530154e-07 9.99960065e-01]\n",
      " [1.96016044e-05 3.29136378e-06 7.90018788e-08 9.99976993e-01]\n",
      " [3.77150827e-05 1.06266916e-05 2.15655945e-07 9.99951482e-01]\n",
      " [2.37523727e-05 9.42371753e-06 1.97813392e-07 9.99966621e-01]\n",
      " [3.69182931e-06 2.47974504e-06 3.29522258e-08 9.99993801e-01]\n",
      " [9.85960560e-06 1.58935854e-05 1.10414646e-07 9.99974132e-01]\n",
      " [3.52093764e-07 5.43189287e-07 6.02842709e-09 9.99999046e-01]\n",
      " [6.72615442e-07 5.62209698e-06 3.66871689e-08 9.99993682e-01]]\n",
      " File name \t forecast category\n",
      "left (130).jpg\tLeft\n",
      "left (134).jpg\tLeft\n",
      "left (138).jpg\tLeft\n",
      "left (141).jpg\tLeft\n",
      "left (145).jpg\tLeft\n",
      "left (146).jpg\tLeft\n",
      "left (147).jpg\tLeft\n",
      "left (148).jpg\tLeft\n",
      "left (151).jpg\tLeft\n",
      "left (152).jpg\tLeft\n",
      "left (155).jpg\tLeft\n",
      "left (160).jpg\tLeft\n",
      "left (175).jpg\tLeft\n",
      "left (178).jpg\tLeft\n",
      "left (39).jpg\tLeft\n",
      "left (53).jpg\tLeft\n",
      "left (68).jpg\tLeft\n",
      "left (72).jpg\tLeft\n",
      "left (87).jpg\tLeft\n",
      "left (91).jpg\tLeft\n",
      "right (10).jpg\tRight\n",
      "right (116).jpg\tRight\n",
      "right (134).jpg\tRight\n",
      "right (135).jpg\tRight\n",
      "right (136).jpg\tRight\n",
      "right (153).jpg\tRight\n",
      "right (171).jpg\tRight\n",
      "right (172).jpg\tRight\n",
      "right (180).jpg\tRight\n",
      "right (191).jpg\tRight\n",
      "right (2).jpg\tRight\n",
      "right (203).jpg\tRight\n",
      "right (204).jpg\tRight\n",
      "right (208).jpg\tRight\n",
      "right (209).jpg\tRight\n",
      "right (210).jpg\tRight\n",
      "right (211).jpg\tRight\n",
      "right (213).jpg\tRight\n",
      "right (224).jpg\tRight\n",
      "right (229).jpg\tRight\n",
      "stop (1).jpg\tStop\n",
      "stop (115).jpg\tStop\n",
      "stop (124).jpg\tStop\n",
      "stop (13).jpg\tStop\n",
      "stop (146).jpg\tStop\n",
      "stop (147).jpg\tStop\n",
      "stop (151).jpg\tStop\n",
      "stop (158).jpg\tStop\n",
      "stop (179).jpg\tStop\n",
      "stop (230).jpg\tStop\n",
      "stop (231).jpg\tStop\n",
      "stop (244).jpg\tStop\n",
      "stop (246).jpg\tStop\n",
      "stop (249).jpg\tStop\n",
      "stop (68).jpg\tStop\n",
      "stop (74).jpg\tStop\n",
      "stop (76).jpg\tStop\n",
      "stop (87).jpg\tStop\n",
      "stop (91).jpg\tStop\n",
      "stop (94).jpg\tStop\n",
      "U_turn (1).jpg\tUTurn\n",
      "U_turn (157).jpg\tUTurn\n",
      "U_turn (167).jpg\tUTurn\n",
      "U_turn (169).jpg\tUTurn\n",
      "U_turn (173).jpg\tUTurn\n",
      "U_turn (179).jpg\tUTurn\n",
      "U_turn (183).jpg\tUTurn\n",
      "U_turn (188).jpg\tUTurn\n",
      "U_turn (191).jpg\tUTurn\n",
      "U_turn (193).jpg\tUTurn\n",
      "U_turn (194).jpg\tUTurn\n",
      "U_turn (2).jpg\tUTurn\n",
      "U_turn (208).jpg\tUTurn\n",
      "U_turn (211).jpg\tUTurn\n",
      "U_turn (214).jpg\tUTurn\n",
      "U_turn (215).jpg\tUTurn\n",
      "U_turn (28).jpg\tUTurn\n",
      "U_turn (41).jpg\tUTurn\n",
      "U_turn (55).jpg\tUTurn\n",
      "U_turn (68).jpg\tUTurn\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#Flatten = 2차원 데이터를 1차원으로 바꿔주는 라이브러리\n",
    "from tensorflow.keras.layers import Dense, Activation, MaxPool2D, Conv2D, Flatten, Dropout, Input, BatchNormalization, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#x=원본데이터\n",
    "def conv_block(x, filters):\n",
    "    x = BatchNormalization() (x)\n",
    "    #padding='same' 원본이미지 사이즈 유지\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same') (x)\n",
    "\n",
    "    x = BatchNormalization() (x)\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same') (x)\n",
    "    x = Add() ([x, shortcut])\n",
    "    x = MaxPool2D((2, 2), strides=(2, 2)) (x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#n_classes = 구분해야할 것의 갯수\n",
    "def custom_model(input_shape, n_classes):\n",
    "\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    #CNN에서 C를 담당\n",
    "    x = conv_block(input_tensor, 32)\n",
    "    x = conv_block(x, 64) #x = image, 64 = filter\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 256)\n",
    "    x = conv_block(x, 512)\n",
    "\n",
    "    x = Flatten() (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = Dense(512, activation='relu') (x)\n",
    "    x = Dense(512, activation='relu') (x)\n",
    "\n",
    "    output_layer = Dense(n_classes, activation='softmax') (x)\n",
    "\n",
    "    inputs = [input_tensor]\n",
    "    model = Model(inputs, output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "          \n",
    "    # Data parameter\n",
    "    input_height = 48\n",
    "    input_width = 48    \n",
    "    input_channel = 3\n",
    "    input_shape = (input_height, input_width, input_channel)\n",
    "    n_classes = 4 # 4 objects = stop, right, left, uturn\n",
    "\n",
    "    # Modeling\n",
    "    # 'custom':\n",
    "    model = custom_model(input_shape, n_classes)\n",
    "  \n",
    "    adam = Adam()\n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['acc'],\n",
    "    )\n",
    "\n",
    "    \n",
    "    data_dir = './data'    \n",
    "    match_obj1 = os.path.join( data_dir, 'Left', '*.jpg')\n",
    "    paths_obj1 = glob.glob(match_obj1)\n",
    "    match_obj2 = os.path.join( data_dir, 'Right', '*.jpg')\n",
    "    paths_obj2 = glob.glob(match_obj2)\n",
    "    match_obj3 = os.path.join( data_dir, 'Stop', '*.jpg')\n",
    "    paths_obj3 = glob.glob(match_obj3)\n",
    "    match_obj4 = os.path.join( data_dir, 'UTurn', '*.jpg')\n",
    "    paths_obj4 = glob.glob(match_obj4)\n",
    "    match_test = os.path.join( data_dir, 'Test', '*.jpg')\n",
    "    paths_test = glob.glob(match_test)\n",
    "\n",
    "    n_train = len(paths_obj1) + len(paths_obj2) + len(paths_obj3) + len(paths_obj4) \n",
    "    n_test = len(paths_test)\n",
    "\n",
    "    # Initialization dataset matrix\n",
    "    trainset = np.zeros(\n",
    "        shape=(n_train, input_height, input_width, input_channel),\n",
    "        dtype='float32',\n",
    "    )\n",
    "    \n",
    "    label = np.zeros(\n",
    "        shape=(n_train, n_classes),\n",
    "        dtype='float32',\n",
    "    )\n",
    "    \n",
    "    testset = np.zeros(\n",
    "        shape=(n_test, input_height, input_width, input_channel),\n",
    "        dtype='float32',\n",
    "    )\n",
    "\n",
    "    # Read image and resize to data set\n",
    "    paths_train = paths_obj1 + paths_obj2 + paths_obj3 + paths_obj4\n",
    "\n",
    "    for ind, path in enumerate(paths_train):      \n",
    "        try:\n",
    "            image = cv2.imread(path)\n",
    "            resized_image = cv2.resize(image, (input_width, input_height))\n",
    "            trainset[ind] = resized_image\n",
    "\n",
    "        except Exception as e:\n",
    "            print(path) # print out the Image that cause exception error\n",
    "        \n",
    "    for ind, path in enumerate(paths_test):\n",
    "        try:\n",
    "            image = cv2.imread(path)\n",
    "            resized_image = cv2.resize(image, (input_width, input_height))\n",
    "            testset[ind] = resized_image\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(path) # print out the Image that cause exception error\n",
    "\n",
    "    # Set the mark of the training set\n",
    "    n_obj1 = len(paths_obj1)\n",
    "    n_obj2 = len(paths_obj2)\n",
    "    n_obj3 = len(paths_obj3)\n",
    "    n_obj4 = len(paths_obj4)\n",
    "  \n",
    "    begin_ind = 0\n",
    "    end_ind = n_obj1\n",
    "    label[begin_ind:end_ind, 0] = 1.0\n",
    "\n",
    "    begin_ind = n_obj1\n",
    "    end_ind = n_obj1 + n_obj2\n",
    "    label[begin_ind:end_ind, 1] = 1.0\n",
    "\n",
    "    begin_ind = n_obj1 + n_obj2\n",
    "    end_ind = n_obj1 + n_obj2 + n_obj3\n",
    "    label[begin_ind:end_ind, 2] = 1.0\n",
    "\n",
    "    begin_ind = n_obj1 + n_obj2 + n_obj3\n",
    "    end_ind = n_obj1 + n_obj2 + n_obj3 + n_obj4\n",
    "    label[begin_ind:end_ind, 3] = 1.0\n",
    "\n",
    "\n",
    "    # Normalize the value between 0 and 1\n",
    "    trainset = trainset / 255.0\n",
    "    testset = testset / 255.0\n",
    "\n",
    "    # Training model\n",
    "    model.fit(\n",
    "        trainset,\n",
    "        label,    \n",
    "        epochs=20,  # no. of rounds of training => 8 rounds\n",
    "        validation_split=0.2,   # percentage of dataset use for validation at trainiing => 20% (2000 images, 1600 for training, 400 for validation)\n",
    "    )\n",
    "\n",
    "    # Saving model architecture and weights (parameters)\n",
    "    model_desc = model.to_json()\n",
    "    model_file = './data/model.json'\n",
    "    with open(model_file, 'w') as file_model:                           \n",
    "        file_model.write(model_desc)\n",
    "\n",
    "    weights_file = './data/weights.h5'\n",
    "    model.save_weights(weights_file )\n",
    "\n",
    "    # Execution predication\n",
    "    if testset.shape[0] != 0:\n",
    "        result_onehot = model.predict(testset)\n",
    "        print(result_onehot)\n",
    "        result_sparse = np.argmax(result_onehot, axis=1)\n",
    "    else:\n",
    "        result_sparse = list()\n",
    "    \n",
    "    # Print predication results\n",
    "    print(' File name \\t forecast category')\n",
    "\n",
    "    for path, label_id in zip(paths_test, result_sparse):\n",
    "        filename = os.path.basename(path)\n",
    "        if label_id == 0:\n",
    "            label_name = 'Left'\n",
    "        elif label_id == 1:\n",
    "            label_name = 'Right'\n",
    "        elif label_id == 2:\n",
    "            label_name = 'Stop'\n",
    "        elif label_id == 3:\n",
    "            label_name = 'UTurn'\n",
    "     \n",
    "        print('%s\\t%s' % (filename, label_name))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
