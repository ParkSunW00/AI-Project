{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Conv2D, Activation, MaxPool2D, Flatten, Dense, Add\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 사용되는 이미지 크기 설정 및 데이터 분류 개수\n",
    "input_height = 48\n",
    "input_width = 48\n",
    "input_channel = 3\n",
    "\n",
    "input_shape = (input_height, input_width, input_channel)\n",
    "n_classes = 5  # left, stop, forward, noSign \n",
    "\n",
    "# 인공지능 학습에 사용되는 이미지 데이터 위치 지정\n",
    "data_dir = './data'\n",
    "data1_path = os.path.join(data_dir, 'Left', '*.jpg')\n",
    "data1_files = glob.glob(data1_path)\n",
    "data2_path = os.path.join(data_dir, 'Forward', '*.jpg')\n",
    "data2_files = glob.glob(data2_path)\n",
    "data3_path = os.path.join(data_dir, 'Stop', '*.jpg')\n",
    "data3_files = glob.glob(data3_path)\n",
    "data4_path = os.path.join(data_dir, 'schoolZone', '*.jpg')\n",
    "data4_files = glob.glob(data4_path)\n",
    "data5_path = os.path.join(data_dir, 'noSign', '*.jpg')\n",
    "data5_files = glob.glob(data5_path)\n",
    "\n",
    "test_path = os.path.join(data_dir, 'Test', '*.jpg')\n",
    "test_files = glob.glob(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 학습에 사용되는 이미지의 총 개수 계산\n",
    "n_train = len(data1_files) + len(data2_files) + len(data3_files) + len(data4_files) + len(data5_files)\n",
    "n_test = len(test_files)\n",
    "print(n_train)\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 학습 데이터 및 레이블이 들어갈 변수 초기화\n",
    "trainset = np.zeros(\n",
    "    shape=(n_train, input_height, input_width, \n",
    "           input_channel), dtype='float32')\n",
    "\n",
    "label = np.zeros(\n",
    "    shape=(n_train, n_classes), dtype='float32')\n",
    "\n",
    "testset = np.zeros(\n",
    "    shape=(n_test, input_height, input_width, \n",
    "           input_channel), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 학습에 사용될 이미지 데이터 파일 전체\n",
    "train_files = data1_files + data2_files + data3_files + data4_files + data5_files\n",
    "# 인공지능 학습에 사용될 이미지 데이터 크기 조정\n",
    "# 훈련데이터 셋에 저장\n",
    "for ind, file in enumerate(train_files):\n",
    "    try:\n",
    "        image = cv2.imread(file)\n",
    "        resized_image = cv2.resize(image,\n",
    "                        (input_width, input_height))\n",
    "        trainset[ind] = resized_image\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "\n",
    "# 인공지능 학습 후 평가를 위해 사용될 이미지 데이터 크기 조정\n",
    "# 평가데이터 셋에 저장\n",
    "for ind, file in enumerate(test_files):\n",
    "    try:\n",
    "        image = cv2.imread(file)\n",
    "        resized_image = cv2.resize(image,\n",
    "                            (input_width, input_height))\n",
    "        testset[ind] = resized_image\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "\n",
    "# 훈련데이터 및 평가데이터를 0과 1 수로 변환\n",
    "trainset = trainset / 255.0\n",
    "testset = testset / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 신호별 데이터 파일 전체 개수 저장\n",
    "n_data1 = len(data1_files)\n",
    "n_data2 = len(data2_files)\n",
    "n_data3 = len(data3_files)\n",
    "n_data4 = len(data4_files)\n",
    "n_data5 = len(data5_files)\n",
    "\n",
    "\n",
    "# 이미지 신호별 레이블 값 정의\n",
    "begin_ind = 0\n",
    "end_ind = n_data1\n",
    "label[begin_ind:end_ind, 0] = 1.0\n",
    "\n",
    "begin_ind = n_data1\n",
    "end_ind = n_data1 + n_data2\n",
    "label[begin_ind:end_ind, 1] = 1.0\n",
    "\n",
    "begin_ind = n_data1 + n_data2\n",
    "end_ind = n_data1 + n_data2 + n_data3\n",
    "label[begin_ind:end_ind, 2] = 1.0\n",
    "\n",
    "begin_ind = n_data1 + n_data2 + n_data3\n",
    "end_ind = n_data1 + n_data2 + n_data3 + n_data4\n",
    "label[begin_ind:end_ind, 3] = 1.0\n",
    "\n",
    "begin_ind = n_data1 + n_data2 + n_data3 + n_data4\n",
    "end_ind = n_data1 + n_data2 + n_data3 + n_data4 + n_data5\n",
    "label[begin_ind:end_ind, 4] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델을 만드는 함수\n",
    "def custom_model(input_shape, n_classes):\n",
    "\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    x = conv_block(input_tensor, 32)\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 256)\n",
    "    x = conv_block(x, 512)\n",
    "\n",
    "    x = Flatten() (x)\n",
    "    x = BatchNormalization() (x)\n",
    "    x = Dense(512, activation='relu') (x)\n",
    "    x = Dense(512, activation='relu') (x)\n",
    "\n",
    "    output_layer = Dense(n_classes, activation='softmax') (x)\n",
    "\n",
    "    inputs = [input_tensor]\n",
    "    model = Model(inputs, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델을 만드는 함수\n",
    "def conv_block(x, filters):\n",
    "    x = BatchNormalization() (x)\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same') (x)\n",
    "\n",
    "    x = BatchNormalization() (x)\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', padding='same') (x)\n",
    "    x = Add() ([x, shortcut])\n",
    "    x = MaxPool2D((2, 2), strides=(2, 2)) (x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 메인함수\n",
    "def main():\n",
    "    \n",
    "    # 모델 함수 호출\n",
    "    model = custom_model(input_shape, n_classes)\n",
    "    \n",
    "    # 인공지능 모델을 이용한 최적 데이터 학습 방법 설계\n",
    "    adam=Adam()\n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # 인공지능 모델을 이용한 데이터 학습 실행\n",
    "    history = model.fit(\n",
    "        trainset, label, \n",
    "        batch_size=20, \n",
    "        epochs=20,  \n",
    "        validation_split=0.005)\n",
    "            \n",
    "    # 인공지능 학습 후 모델 파일(model.json) 저장\n",
    "    # 가중치 값 파일(weights.h5) 저장\n",
    "    model_desc = model.to_json()\n",
    "    with open('./model/model.json', 'w') as file_model:\n",
    "        file_model.write(model_desc)\n",
    "    model.save_weights('./model/weights.h5')\n",
    "\n",
    "    # 평가데이터를 이용한 예측 정확도 확인\n",
    "    if testset.shape[0] != 0:\n",
    "        result_onehot = model.predict(testset)\n",
    "        result_predict = np.argmax(result_onehot, axis=1)\n",
    "    else:\n",
    "        result_sparse = list()\n",
    "\n",
    "    print('File name\\t forecast category')\n",
    "\n",
    "    # 평가 데이터 파일명에 따른 예측 결과 값 출력\n",
    "    for file, label_id in zip(test_files, result_predict):\n",
    "        \n",
    "        filename = os.path.basename(file)\n",
    "        \n",
    "        if label_id == 0:\n",
    "            label_name = 'Left'\n",
    "        elif label_id == 1:\n",
    "            label_name = 'Forward'\n",
    "        elif label_id == 2:\n",
    "            label_name = 'Stop'\n",
    "        elif label_id == 3:\n",
    "            label_name = 'School Zone'\n",
    "        elif label_id == 4:\n",
    "            label_name = 'noSign'\n",
    "\n",
    "        print('%s\\t%s' % (filename, label_name))\n",
    "        \n",
    "    # 모델 요약 및 학습 진행 결과 출력\n",
    "    model.summary()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
